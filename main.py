import os
import torch
from preprocessing import create_data_loaders
from models import ArtStyleCNN, get_resnet_model
from train_utils import train_model
import torch.nn as nn
import torch.optim as optim

if __name__ == "__main__":
    print("\nDane cuda:")
    print(torch.__version__)                     # np. 2.6.0+cu118
    print(torch.version.cuda)                    # np. '11.8' je≈õli CUDA dzia≈Ça
    print(torch.cuda.is_available())             # True tylko je≈õli dzia≈Ça GPU
    print("\n")

    # ≈õcie≈ºki do katalog√≥w
    #Dominik
    # input_directory = r"C:\Users\Dominik\Desktop\DataSet"
    # output_directory = r"C:\Users\Dominik\Desktop\outData"
    
    #Karolina
    input_directory = r"C:\Users\kkuro\Desktop\Studia\semestr_6\Podstawy_AI\DataSet"
    output_directory = r"C:\Users\kkuro\Desktop\Studia\semestr_6\Podstawy_AI\outData"

    # Parametry
    img_size = 224
    batch_size = 32
    start_epoch = 10       # liczba epok ju≈º przeprowadzonych
    total_epochs = 15       # do ilu epok chcesz dociƒÖgnƒÖƒá model
    continue_training = True 

    # ≈öcie≈ºki wyj≈õciowe
    processed_dir = os.path.join(output_directory, "processed")
    split_dir = os.path.join(output_directory, "split")

    data_loaders = create_data_loaders(split_dir, batch_size=batch_size, img_size=img_size)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"U≈ºywane urzƒÖdzenie: {device}")

    num_classes = len(data_loaders['train_dataset'].label_to_idx)

    models_to_train = {
        "CustomCNN": ArtStyleCNN(num_classes),
        #"ResNet18_pretrained": get_resnet_model(num_classes, pretrained=True),
        #"ResNet18_scratch": get_resnet_model(num_classes, pretrained=False)
    }
    
    for model_name, model in models_to_train.items():
        print(f"\nüß† Trenujƒô model: {model_name}")
    
        if continue_training:
            checkpoint_path = os.path.join("models", model_name, "best_model.pt")
            if os.path.exists(checkpoint_path):
                print(f"üîÑ Wczytywanie modelu z {checkpoint_path}")
                model.load_state_dict(torch.load(checkpoint_path, map_location=device))
            else:
                print(f"‚ö†Ô∏è Nie znaleziono {checkpoint_path}. Trening rozpocznie siƒô od zera.")

        model = model.to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

        try:
            history, final_metrics = train_model(model, 
                                                data_loaders['train_loader'], 
                                                data_loaders['val_loader'], 
                                                criterion, optimizer, 
                                                device, 
                                                model_name=model_name,
                                                num_epochs=total_epochs - start_epoch,
                                                start_epoch=start_epoch
                                                )
            print(f"‚úÖ Trenowanie zako≈Ñczone dla modelu {model_name}")
            print("\nüìã Podsumowanie treningu:")
            print(f"Najlepsza dok≈Çadno≈õƒá walidacyjna: {max(history['Dok≈Çadno≈õƒá_walidacyjna']):.2f}%")
            print(f"Finalne metryki:")
            print(f" - Accuracy: {final_metrics[0]:.2f}%")
            print(f" - Precision: {final_metrics[2]:.4f}")
            print(f" - Recall: {final_metrics[3]:.4f}")
            print(f" - F1-Score: {final_metrics[4]:.4f}")
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd w modelu {model_name}: {e}")
