import os
import torch
from preprocessing import create_data_loaders
from models import ArtStyleCNN, get_resnet_model
from train_utils import train_model
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import matplotlib.pyplot as plt

if __name__ == "__main__":
    print("\nDane cuda:")
    print(torch.__version__)                     # np. 2.6.0+cu118
    print(torch.version.cuda)                    # np. '11.8' jeÅ›li CUDA dziaÅ‚a
    print(torch.cuda.is_available())             # True tylko jeÅ›li dziaÅ‚a GPU
    print("\n")

    # Å›cieÅ¼ki do katalogÃ³w
    #Dominik
    input_directory = r"C:\Users\Dominik\Desktop\DataSet"
    output_directory = r"C:\Users\Dominik\Desktop\outData"
    
    #Karolina
    #input_directory = r"C:\Users\kkuro\Desktop\Studia\semestr_6\Podstawy_AI\DataSet"
    #output_directory = r"C:\Users\kkuro\Desktop\Studia\semestr_6\Podstawy_AI\outData"

    # Parametry
    img_size = 224
    batch_size = 32
    
    start_epoch = 15        # liczba epok juÅ¼ przeprowadzonych
    total_epochs = 17        # do ilu epok chcesz dociÄ…gnÄ…Ä‡ model
    continue_training = True 

    # ÅšcieÅ¼ki wyjÅ›ciowe
    processed_dir = os.path.join(output_directory, "processed")
    split_dir = os.path.join(output_directory, "split")

    data_loaders = create_data_loaders(split_dir, batch_size=batch_size, img_size=img_size)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"UÅ¼ywane urzÄ…dzenie: {device}")

    num_classes = len(data_loaders['train_dataset'].label_to_idx)

    models_to_train = {
        #"CustomCNN": ArtStyleCNN(num_classes),
        "ResNet18_pretrained": get_resnet_model(num_classes, pretrained=True),
        #"ResNet18_scratch": get_resnet_model(num_classes, pretrained=False)
    }
    
    for model_name, model in models_to_train.items():
        print(f"\nğŸ§  TrenujÄ™ model: {model_name}")

        # ÅšcieÅ¼ki do modelu i historii treningu
        models_dir = "Models"  # Folder na modele
        metrics_dir = "Metrics"  # Poprawiony folder name typo "Matrics" -> "Metrics"
        
        # Upewnij siÄ™, Å¼e foldery istniejÄ…
        os.makedirs(models_dir, exist_ok=True)
        os.makedirs(metrics_dir, exist_ok=True)
        
        # ÅšcieÅ¼ki do plikÃ³w
        model_path = os.path.join(models_dir, f"{model_name}_best_model.pt")
        history_path = os.path.join(metrics_dir, f'{model_name}_training_history.csv')
        
        # Inicjalizuj start_epoch
        start_epoch = 0
        
        # Wczytywanie historii treningu (jeÅ›li istnieje)
        previous_history = None
        if continue_training and os.path.exists(history_path):
            previous_history = pd.read_csv(history_path)
            print(f"ğŸ“Š Wczytano historiÄ™ treningu z {history_path} ({len(previous_history)} epok)")

            if len(previous_history) > 0:
                # Zapisz najwyÅ¼szÄ… epokÄ™ z poprzedniej historii
                start_epoch = int(previous_history['Epoka'].max())+1
                max_previous_epoch = previous_history['Epoka'].max()
                last_val_acc = previous_history['DokÅ‚adnoÅ›Ä‡_walidacyjna'].iloc[-1]
                print(f"ğŸ“ˆ Ostatnia zapisana epoka: {max_previous_epoch}, dokÅ‚adnoÅ›Ä‡ walidacyjna: {last_val_acc:.2f}%")
                # W przypadku wznowienia treningu, moÅ¼emy zaczÄ…Ä‡ od epoki 1, ale bÄ™dziemy wiedzieÄ‡
                # Å¼e musimy przesunÄ…Ä‡ numeracjÄ™ przy Å‚Ä…czeniu historii
        
        # Wczytywanie modelu (jeÅ›li kontynuujemy trening)
        if continue_training:
            if os.path.exists(model_path):
                print(f"ğŸ”„ Wczytywanie modelu z {model_path}")
                model.load_state_dict(torch.load(model_path, map_location=device))
            else:
                print(f"âš ï¸ Nie znaleziono {model_path}. Trening rozpocznie siÄ™ od zera.")
                previous_history = None  # Reset poprzedniej historii gdy nie ma zapisanego modelu

        model = model.to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

        try:
            # Trenuj model
            # Tutaj nie przekazujemy start_epoch, bo funkcja train_model najprawdopodobniej
            # zawsze zaczyna od epoki 1, co widaÄ‡ w danych CSV
            history_df, final_metrics = train_model(model, 
                                            data_loaders['train_loader'], 
                                            data_loaders['val_loader'], 
                                            criterion, optimizer, 
                                            device, 
                                            model_name=model_name,
                                            num_epochs=total_epochs - start_epoch,
                                            start_epoch=start_epoch 
                                            )
            
            print(f"âœ… Trenowanie zakoÅ„czone dla modelu {model_name}")
            
            # Zapisz nowÄ… historiÄ™ jako CSV
            if history_df is not None:
                # ÅÄ…czenie z poprzedniÄ… historiÄ… (jeÅ›li istnieje)
                if previous_history is not None:
                    # PrzesuÅ„ numeracjÄ™ epok w nowej historii, aby kontynuowaÄ‡ po ostatniej epoce z poprzedniej historii
                    max_previous_epoch = previous_history['Epoka'].max()
                    print(f"ğŸ”¢ Przesuwanie numeracji epok o {max_previous_epoch} (kontynuacja po epoce {max_previous_epoch})")
                    
                    # Dostosowujemy numeracjÄ™ nowych epok, aby kontynuowaÄ‡ po poprzednich
                    history_df['Epoka'] = history_df['Epoka'] + max_previous_epoch
                    
                    # ÅÄ…czymy historie
                    full_history = pd.concat([previous_history, history_df], ignore_index=True)
                    
                    # Dla pewnoÅ›ci sortujemy po numerze epoki
                    full_history = full_history.sort_values('Epoka').reset_index(drop=True)
                else:
                    full_history = history_df
                
                # Zapisz peÅ‚nÄ… historiÄ™
                full_history.to_csv(history_path, index=False)
                print(f"ğŸ’¾ Zapisano peÅ‚nÄ… historiÄ™ treningu do {history_path}")
                
                # Rysuj peÅ‚nÄ… historiÄ™ treningu
                plot_dir = os.path.join("training_plots", model_name)
                os.makedirs(plot_dir, exist_ok=True)
                
                plt.figure(figsize=(12, 5))
                plt.suptitle(f'{model_name} â€“ PeÅ‚na historia treningu ({len(full_history)} epok)', fontsize=16)
                
                # Wykres funkcji straty
                plt.subplot(1, 2, 1)
                plt.plot(full_history['Epoka'], full_history['Strata_treningowa'], 'b-', label='Strata treningowa')
                plt.plot(full_history['Epoka'], full_history['Strata_walidacyjna'], 'r-', label='Strata walidacyjna')
                plt.title('Funkcje straty')
                plt.xlabel('Epoki')
                plt.ylabel('Strata')
                plt.legend()
                plt.grid(True, linestyle='--', alpha=0.7)
                
                # Wykres dokÅ‚adnoÅ›ci
                plt.subplot(1, 2, 2)
                plt.plot(full_history['Epoka'], full_history['DokÅ‚adnoÅ›Ä‡_treningowa'], 'b-', label='DokÅ‚adnoÅ›Ä‡ treningowa')
                plt.plot(full_history['Epoka'], full_history['DokÅ‚adnoÅ›Ä‡_walidacyjna'], 'r-', label='DokÅ‚adnoÅ›Ä‡ walidacyjna')
                plt.title('DokÅ‚adnoÅ›Ä‡')
                plt.xlabel('Epoki')
                plt.ylabel('DokÅ‚adnoÅ›Ä‡ [%]')
                plt.legend()
                plt.grid(True, linestyle='--', alpha=0.7)
                
                # Dodaj etykiety dla poszczegÃ³lnych sesji treningowych
                if previous_history is not None:
                    # Dodaj pionowÄ… liniÄ™ rozdzielajÄ…cÄ… sesje treningowe
                    max_previous_epoch = previous_history['Epoka'].max()
                    plt.subplot(1, 2, 1)
                    plt.axvline(x=max_previous_epoch, color='green', linestyle='--', alpha=0.7)
                    plt.text(max_previous_epoch+0.1, plt.ylim()[1]*0.9, 'Nowa sesja', 
                            rotation=90, color='green', verticalalignment='top')
                    
                    plt.subplot(1, 2, 2)
                    plt.axvline(x=max_previous_epoch, color='green', linestyle='--', alpha=0.7)
                    plt.text(max_previous_epoch+0.1, plt.ylim()[1]*0.9, 'Nowa sesja', 
                            rotation=90, color='green', verticalalignment='top')
                
                plt.tight_layout()
                
                full_history_plot_path = os.path.join(plot_dir, f"{model_name}_full_training_history.png")
                plt.savefig(full_history_plot_path)
                print(f"ğŸ“Š Zapisano peÅ‚nÄ… historiÄ™ treningu do {full_history_plot_path}")
            
            if final_metrics:
                print("\nğŸ“‹ Podsumowanie treningu:")
                if history_df is not None and 'DokÅ‚adnoÅ›Ä‡_walidacyjna' in history_df:
                    # ZnajdÅº najlepszÄ… dokÅ‚adnoÅ›Ä‡ w nowej sesji treningowej
                    max_val_acc = max(history_df['DokÅ‚adnoÅ›Ä‡_walidacyjna'])
                    epoch_with_max = history_df.loc[history_df['DokÅ‚adnoÅ›Ä‡_walidacyjna'].idxmax(), 'Epoka']
                    print(f"Najlepsza dokÅ‚adnoÅ›Ä‡ walidacyjna w tej sesji: {max_val_acc:.2f}% (epoka {epoch_with_max})")
                    
                    if previous_history is not None:
                        # ZnajdÅº najlepszÄ… dokÅ‚adnoÅ›Ä‡ we wszystkich epokach
                        overall_max_val_acc = max(full_history['DokÅ‚adnoÅ›Ä‡_walidacyjna'])
                        overall_best_epoch = full_history.loc[full_history['DokÅ‚adnoÅ›Ä‡_walidacyjna'].idxmax(), 'Epoka']
                        print(f"Najlepsza dokÅ‚adnoÅ›Ä‡ walidacyjna ogÃ³Å‚em: {overall_max_val_acc:.2f}% (epoka {overall_best_epoch})")
                
                print(f"Finalne metryki:")
                print(f" - Accuracy: {final_metrics[0]:.2f}%")
                print(f" - Precision: {final_metrics[2]:.4f}")
                print(f" - Recall: {final_metrics[3]:.4f}")
                print(f" - F1-Score: {final_metrics[4]:.4f}")
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d w modelu {model_name}: {e}")
            import traceback
            traceback.print_exc()
