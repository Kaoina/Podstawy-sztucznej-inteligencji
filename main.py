import os
import torch
from preprocessing import create_data_loaders
from models import ArtStyleCNN, get_resnet_model
from train_utils import train_model
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import matplotlib.pyplot as plt

if __name__ == "__main__":
    print("\nDane cuda:")
    print(torch.__version__)                     # np. 2.6.0+cu118
    print(torch.version.cuda)                    # np. '11.8' je≈õli CUDA dzia≈Ça
    print(torch.cuda.is_available())             # True tylko je≈õli dzia≈Ça GPU
    print("\n")

    # ≈õcie≈ºki do katalog√≥w
    #Dominik
    input_directory = r"C:\Users\Dominik\Desktop\DataSet"
    output_directory = r"C:\Users\Dominik\Desktop\outData"
    
    #Karolina
    #input_directory = r"C:\Users\kkuro\Desktop\Studia\semestr_6\Podstawy_AI\DataSet"
    #output_directory = r"C:\Users\kkuro\Desktop\Studia\semestr_6\Podstawy_AI\outData"

    # === Parametry === 
    img_size = 224
    batch_size = 32
    
    total_epochs = 17        # do ilu epok chcesz dociƒÖgnƒÖƒá model
    continue_training = True 

    # ≈öcie≈ºki wyj≈õciowe
    processed_dir = os.path.join(output_directory, "processed")
    split_dir = os.path.join(output_directory, "split")
    #history_path = "ResNet18_pretrainded_training_history" 

    data_loaders = create_data_loaders(split_dir, batch_size=batch_size, img_size=img_size)

    num_classes = len(data_loaders['train_dataset'].label_to_idx)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"U≈ºywane urzƒÖdzenie: {device}")

    models_to_train = {
        #"CustomCNN": ArtStyleCNN(num_classes),
        "ResNet18_pretrained": get_resnet_model(num_classes, pretrained=True),
        #"ResNet18_scratch": get_resnet_model(num_classes, pretrained=False)
    }
    
    for model_name, model in models_to_train.items():

        # ≈öcie≈ºki do modelu i historii treningu
        model_dir = os.path.join("Models", model_name)
        metrics_dir = os.path.join("Metrics", model_name)
            
        os.makedirs(model_dir, exist_ok=True)
        os.makedirs(metrics_dir, exist_ok=True)

        # ≈öcie≈ºki do plik√≥w
        model_path = os.path.join(model_dir, f"best_model.pt")
        history_path = os.path.join(model_dir, f'{model_name}_training_history.csv')
        
        start_epoch = 0
        previous_history = None

        if continue_training and os.path.exists(history_path):
            previous_history = pd.read_csv(history_path)
            print(f"üìä Wczytano historiƒô treningu z {history_path} ({len(previous_history)} epok)")

            if len(previous_history) > 0:
                # Zapisz najwy≈ºszƒÖ epokƒô z poprzedniej historii
                start_epoch = int(previous_history['Epoka'].max())
                max_previous_epoch = previous_history['Epoka'].max()
                last_val_acc = previous_history['Dok≈Çadno≈õƒá_walidacyjna'].iloc[-1]
                print(f"üìà Ostatnia zapisana epoka: {max_previous_epoch}, dok≈Çadno≈õƒá walidacyjna: {last_val_acc:.2f}%")
       
        # Wczytywanie modelu 
        if continue_training:
            if os.path.exists(model_path):
                print(f"üîÑ Wczytywanie modelu z {model_path}")
                model.load_state_dict(torch.load(model_path, map_location=device))
            else:
                print(f"‚ö†Ô∏è Nie znaleziono {model_path}. Trening rozpocznie siƒô od zera.")
                previous_history = None  # Reset poprzedniej historii gdy nie ma zapisanego modelu

        model = model.to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

        try:

            epochs_to_train = total_epochs - int(previous_history['Epoka'].max())

            if epochs_to_train <= 0:
                print(f"‚ö†Ô∏è Model juz zostal wytenowany do podanej epoki")
                break


            print(f"\nüß† Trenujƒô model: {model_name}")

            history_df, final_metrics = train_model(model, 
                                            data_loaders['train_loader'], 
                                            data_loaders['val_loader'], 
                                            criterion, optimizer, 
                                            device, 
                                            model_name=model_name,
                                            num_epochs=epochs_to_train,
                                            start_epoch=start_epoch 
                                            )
            
            print(f"‚úÖ Trenowanie zako≈Ñczone dla modelu {model_name}")
            
            # Zapisz historiƒô jako CSV
            if history_df is not None:
                if previous_history is not None:

                    # max_previous_epoch = previous_history['Epoka'].max()
                    # history_df['Epoka'] = history_df['Epoka'] + max_previous_epoch
                    
                    # ≈ÅƒÖczymy historie
                    full_history = pd.concat([previous_history, history_df], ignore_index=True)
                    full_history = full_history.sort_values('Epoka').reset_index(drop=True)

                else:
                    full_history = history_df
                

                # Zapisz pe≈ÇnƒÖ historiƒô
                full_history.to_csv(history_path, index=False)
                print(f"üíæ Zapisano pe≈ÇnƒÖ historiƒô treningu do {history_path}")
                
                # Rysuj pe≈ÇnƒÖ historiƒô treningu
                # plot_dir = os.path.join("Models", model_name)
                # os.makedirs(plot_dir, exist_ok=True)
                
                plt.figure(figsize=(12, 5))
                plt.suptitle(f'{model_name} ‚Äì Pe≈Çna historia treningu ({len(full_history)} epok)', fontsize=16)
                
                # Wykres funkcji straty
                plt.subplot(1, 2, 1)
                plt.plot(full_history['Epoka'], full_history['Strata_treningowa'], 'b-', label='Strata treningowa')
                plt.plot(full_history['Epoka'], full_history['Strata_walidacyjna'], 'r-', label='Strata walidacyjna')
                plt.title('Funkcje straty')
                plt.xlabel('Epoki')
                plt.ylabel('Strata')
                plt.legend()
                plt.grid(True, linestyle='--', alpha=0.7)
                
                # Wykres dok≈Çadno≈õci
                plt.subplot(1, 2, 2)
                plt.plot(full_history['Epoka'], full_history['Dok≈Çadno≈õƒá_treningowa'], 'b-', label='Dok≈Çadno≈õƒá treningowa')
                plt.plot(full_history['Epoka'], full_history['Dok≈Çadno≈õƒá_walidacyjna'], 'r-', label='Dok≈Çadno≈õƒá walidacyjna')
                plt.title('Dok≈Çadno≈õƒá')
                plt.xlabel('Epoki')
                plt.ylabel('Dok≈Çadno≈õƒá [%]')
                plt.legend()
                plt.grid(True, linestyle='--', alpha=0.7)
                
                # Dodaj etykiety dla poszczeg√≥lnych sesji treningowych
                if previous_history is not None:

                    # Dodaj pionowƒÖ liniƒô rozdzielajƒÖcƒÖ sesje treningowe
                    max_previous_epoch = previous_history['Epoka'].max()
                    plt.subplot(1, 2, 1)
                    plt.axvline(x=max_previous_epoch, color='green', linestyle='--', alpha=0.7)
                    plt.text(max_previous_epoch+0.1, plt.ylim()[1]*0.9, 'Nowa sesja', 
                            rotation=90, color='green', verticalalignment='top')
                    
                    plt.subplot(1, 2, 2)
                    plt.axvline(x=max_previous_epoch, color='green', linestyle='--', alpha=0.7)
                    plt.text(max_previous_epoch+0.1, plt.ylim()[1]*0.9, 'Nowa sesja', 
                            rotation=90, color='green', verticalalignment='top')
                
                plt.tight_layout()
                
                full_history_plot_path = os.path.join(metrics_dir, f"{model_name}_full_training_history.png")
                plt.savefig(full_history_plot_path)
                print(f"üìä Zapisano pe≈ÇnƒÖ historiƒô treningu do {full_history_plot_path}")
            

            # Mozna zostawic tylko wydruk Finalne metryki
            if final_metrics:
                print("\nüìã Podsumowanie treningu:")
                if history_df is not None and 'Dok≈Çadno≈õƒá_walidacyjna' in history_df:
                    # Znajd≈∫ najlepszƒÖ dok≈Çadno≈õƒá w nowej sesji treningowej
                    max_val_acc = max(history_df['Dok≈Çadno≈õƒá_walidacyjna'])
                    epoch_with_max = history_df.loc[history_df['Dok≈Çadno≈õƒá_walidacyjna'].idxmax(), 'Epoka']
                    print(f"Najlepsza dok≈Çadno≈õƒá walidacyjna w tej sesji: {max_val_acc:.2f}% (epoka {epoch_with_max})")
                    
                    if previous_history is not None:
                        # Znajd≈∫ najlepszƒÖ dok≈Çadno≈õƒá we wszystkich epokach
                        overall_max_val_acc = max(full_history['Dok≈Çadno≈õƒá_walidacyjna'])
                        overall_best_epoch = full_history.loc[full_history['Dok≈Çadno≈õƒá_walidacyjna'].idxmax(), 'Epoka']
                        print(f"Najlepsza dok≈Çadno≈õƒá walidacyjna og√≥≈Çem: {overall_max_val_acc:.2f}% (epoka {overall_best_epoch})")
                
                print(f"Finalne metryki:")
                print(f" - Accuracy: {final_metrics[0]:.2f}%")
                print(f" - Precision: {final_metrics[2]:.4f}")
                print(f" - Recall: {final_metrics[3]:.4f}")
                print(f" - F1-Score: {final_metrics[4]:.4f}")
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd w modelu {model_name}: {e}")
            import traceback
            traceback.print_exc()
